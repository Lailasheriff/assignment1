{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "### This script performs lane detection in an image using Hough Transform, The steps involved are:\n",
    "#### 1.⁠ ⁠*Load Image*: Read the image from the file.\n",
    "#### 2.⁠ ⁠*Preprocess Image*: Convert it to grayscale, apply blurring, and detect edges.\n",
    "#### 3.⁠ ⁠*Region of Interest (ROI)*: Select only the road area to reduce noise.\n",
    "#### 4.⁠ ⁠*Hough Transform*: Detect lane lines by accumulating votes in Hough space.\n",
    "#### 5.⁠ ⁠*Overlay Lines*: Superimpose detected lanes on the original image.\n",
    "#### 6.⁠ ⁠*Display Results*: Show the outputs at different stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load image\n",
    "image = cv2.imread(\"road2.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the image by converting to grayscale, applying a median blur, and detecting edges\n",
    "#### 1. Convert the image to grayscale to simplify processing\n",
    "#### 2. Apply a median blur to reduce noise while preserving edges\n",
    "#### 3. Use the Canny edge detector to extract edges from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.medianBlur(gray, 5)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masks the image to focus only on region of interest (the lane lines)\n",
    "#### it creates a mask in the shape of a polygon covering the road area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI(edges):\n",
    "    height, width = edges.shape\n",
    "    mask = np.zeros_like(edges)\n",
    "    polygon = np.array([[(100, height), (width//2 - 100, height//2 + 50), \n",
    "                         (width//2 + 100, height//2 + 50), (width-100, height)]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, polygon, 255)\n",
    "    masked_edges = cv2.bitwise_and(edges, mask)\n",
    "    return masked_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_maximum_suppression(accumulator, threshold):\n",
    "    suppressed = np.zeros_like(accumulator)\n",
    "    for i in range(1, accumulator.shape[0] - 1):\n",
    "        for j in range(1, accumulator.shape[1] - 1):\n",
    "            local_patch = accumulator[i-1:i+2, j-1:j+2]\n",
    "            if accumulator[i, j] == np.max(local_patch) and accumulator[i, j] > threshold:\n",
    "                suppressed[i, j] = accumulator[i, j]\n",
    "    return suppressed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### detects lines by accumulating votes in the Hough space in the edge-detected image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_transform(edges, image):\n",
    "    height, width = edges.shape\n",
    "    max_dist = int(math.sqrt(height**2 + width**2))  #Maximum possible rho value\n",
    "    theta_range = np.deg2rad(np.arange(-90, 90))  # -90 to 90 degrees\n",
    "    accumulator = np.zeros((2 * max_dist + 1, len(theta_range)), dtype=np.int32) \n",
    "    edge_points = np.argwhere(edges)  # Get all nonzero edge pixels\n",
    "\n",
    "    #Accumulate votes in Hough space\n",
    "    for y, x in edge_points:\n",
    "        for t_idx, theta in enumerate(theta_range):\n",
    "            rho = int(x * np.cos(theta) + y * np.sin(theta)) + max_dist  # Ensure non-negative index\n",
    "            if 0 <= rho < accumulator.shape[0]: #Checking bounds\n",
    "                accumulator[rho, t_idx] += 1\n",
    "\n",
    "    accumulator = non_maximum_suppression(accumulator, threshold=100)\n",
    "    lines = [(r - max_dist, theta_range[t]) for r, t in np.argwhere(accumulator > 0)]\n",
    "\n",
    "    #draw the detected lines on a blank image\n",
    "    line_image = np.zeros_like(image)\n",
    "\n",
    "    #convert it to cartesian\n",
    "    for rho, theta in lines:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "\n",
    "        #Define lane region limits\n",
    "        y1 = height #Bottom of image\n",
    "        y2 = int(height * 0.6) #Top limit for lane line\n",
    "\n",
    "        #calculate corresponding x values\n",
    "        if a != 0:\n",
    "            x1 = int((rho - y1 * b) / a)\n",
    "            x2 = int((rho - y2 * b) / a)\n",
    "        else:\n",
    "            x1, x2 = x0, x0 \n",
    "\n",
    "        cv2.line(line_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "    print(\"Accumulator Matrix:\")\n",
    "    print(accumulator)    \n",
    "    return line_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlay detected lane lines into the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_lines(image, lines):\n",
    "    return cv2.addWeighted(image, 0.8, lines, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process image\n",
    "edges = preprocess_image(image)\n",
    "roi_edges = ROI(edges)\n",
    "line_image = hough_transform(roi_edges, image)\n",
    "final_image = overlay_lines(image, line_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))  \n",
    "axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  #Convert BGR to RGB for correct display\n",
    "axes[0, 0].set_title(\"Original Image\")\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title(\"Lane Detection Output\")\n",
    "axes[0, 1].axis(\"off\")\n",
    "\n",
    "axes[1, 0].imshow(edges, cmap=\"gray\")\n",
    "axes[1, 0].set_title(\"Edge Detection Output\")\n",
    "axes[1, 0].axis(\"off\")\n",
    "\n",
    "axes[1, 1].imshow(roi_edges, cmap=\"gray\")\n",
    "axes[1, 1].set_title(\"ROI Output\")\n",
    "axes[1, 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"edge_output.png\", edges)\n",
    "cv2.imwrite(\"roi_output.png\", roi_edges)\n",
    "cv2.imwrite(\"lane_detection.png\", final_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
